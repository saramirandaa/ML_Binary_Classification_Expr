# üé≠ Detector de Expresiones Faciales Gramaticales (Libras)

Sistema de reconocimiento en tiempo real de expresiones faciales gramaticales utilizadas en la Lengua de Se√±as Brasile√±a (Libras), basado en Machine Learning y MediaPipe Face Mesh.

## üìã Descripci√≥n del Proyecto

Este proyecto implementa un clasificador binario de expresiones faciales que identifica gestos gramaticales no manuales utilizados en Libras. El sistema captura puntos faciales (landmarks) mediante webcam y predice la expresi√≥n en tiempo real usando un modelo de Machine Learning entrenado.

###  Caracter√≠sticas Principales

- **Detecci√≥n facial en tiempo real** con MediaPipe Face Mesh (468 landmarks)
- **Clasificaci√≥n binaria** de expresiones faciales gramaticales
- **Sistema de calibraci√≥n** para mejorar la precisi√≥n
- **Suavizado de predicciones** mediante historial temporal
- **M√∫ltiples implementaciones** optimizadas para diferentes casos de uso
- **Interfaz visual interactiva** con controles por teclado

##  Arquitectura del Sistema

### Componentes Principales

```
‚îú‚îÄ‚îÄ final.ipynb                          # Notebook de entrenamiento y an√°lisis EDA
‚îú‚îÄ‚îÄ grammatical_facial_expressions.csv   # Dataset de entrenamiento
‚îú‚îÄ‚îÄ modelo_facial_expressions.pkl        # Modelo entrenado
‚îú‚îÄ‚îÄ scaler_facial_expressions.pkl        # Scaler para normalizaci√≥n
‚îú‚îÄ‚îÄ modelo_info.pkl                      # Metadata del modelo
‚îú‚îÄ‚îÄ ExtractLandmarks.py                  # Extracci√≥n de 100 landmarks clave
‚îú‚îÄ‚îÄ predict_expression.py                # Motor de predicci√≥n
‚îú‚îÄ‚îÄ FaceCapture.py                       # Captura b√°sica de rostro
‚îú‚îÄ‚îÄ main.py                              # Sistema b√°sico de detecci√≥n
‚îú‚îÄ‚îÄ main_calibrated.py                   # Sistema con calibraci√≥n
‚îú‚îÄ‚îÄ main_optimized.py                    # Sistema optimizado
‚îî‚îÄ‚îÄ test_prediction.py                   # Script de pruebas
```

### Pipeline de Procesamiento

```
Webcam ‚Üí MediaPipe Face Mesh ‚Üí Extracci√≥n de 100 Landmarks 
‚Üí Vector de 301 caracter√≠sticas ‚Üí Normalizaci√≥n (opcional) 
‚Üí Modelo ML ‚Üí Predicci√≥n (0 o 1) ‚Üí Visualizaci√≥n
```

## üî¨ Metodolog√≠a de Machine Learning

### Dataset

- **Formato**: 301 caracter√≠sticas por muestra
  - 1 timestamp
  - 100 landmarks √ó 3 coordenadas (x, y, z) = 300 valores
- **Tipo**: Clasificaci√≥n binaria (0/1)
- **Preprocesamiento**: Valores en p√≠xeles absolutos

### Modelos Evaluados

El notebook `final.ipynb` entrena y compara m√∫ltiples algoritmos:

-  **Random Forest** (mejor rendimiento)
- Support Vector Machine (Linear y RBF)
- K-Nearest Neighbors
- Naive Bayes
- Decision Tree
- Gradient Boosting
- AdaBoost
- Neural Network (MLP)
- Linear Discriminant Analysis (LDA)

### M√©tricas de Evaluaci√≥n

- Accuracy
- Precision
- Recall
- F1-Score
- Matriz de Confusi√≥n
- Tiempo de entrenamiento

### An√°lisis Exploratorio (EDA)

- Visualizaci√≥n con LDA para separaci√≥n de clases
- Profiling completo del dataset con `ydata-profiling`
- An√°lisis de distribuci√≥n de caracter√≠sticas

##  Instalaci√≥n

### Requisitos Previos

- Python 3.11+
- Webcam funcional
- Windows/Linux/MacOS

### Paso 1: Clonar el Repositorio

```bash
git clone https://github.com/AVillafana12/final.git
cd final
```

### Paso 2: Crear Entorno Virtual

```bash
# Windows PowerShell
python -m venv env
.\env\Scripts\Activate.ps1

# Linux/Mac
python3 -m venv env
source env/bin/activate
```

### Paso 3: Instalar Dependencias

```bash
pip install -r requirements.txt
```

### Dependencias Principales

```
opencv-python==4.10.0.84
mediapipe==0.10.14
scikit-learn==1.6.1
pandas==2.2.0
numpy==2.2.6
matplotlib==3.10.0
seaborn==0.13.2
ydata-profiling==4.13.1
```

## üíª Uso del Sistema

### Opci√≥n 1: Sistema B√°sico

```bash
python main.py
```

**Caracter√≠sticas**:
- Detecci√≥n y predicci√≥n en tiempo real
- Visualizaci√≥n de Face Mesh completo
- Sin calibraci√≥n

### Opci√≥n 2: Sistema Calibrado (Recomendado)

```bash
python main_calibrated.py
```

**Caracter√≠sticas**:
- Sistema de calibraci√≥n inicial (30 frames en posici√≥n neutral)
- Suavizado de predicciones con historial
- Umbral ajustable en tiempo real
- Controles interactivos avanzados

**Controles**:
- `ESPACIO`: Iniciar/reiniciar calibraci√≥n
- `L`: Alternar visualizaci√≥n de todos los landmarks
- `G`: Mostrar/ocultar gu√≠a de expresiones
- `+/-`: Ajustar umbral de detecci√≥n
- `Q`: Salir

### Opci√≥n 3: Sistema Optimizado

```bash
python main_optimized.py
```

**Caracter√≠sticas**:
- Extracci√≥n optimizada de landmarks
- Mayor rendimiento
- Calibraci√≥n autom√°tica

### Script de Pruebas

Verificar el funcionamiento del modelo con datos del dataset:

```bash
python test_prediction.py
```

##  Entrenamiento del Modelo

### Ejecutar Notebook de Entrenamiento

1. Abrir `final.ipynb` en Jupyter Notebook o VS Code
2. Ejecutar todas las celdas secuencialmente
3. El notebook realizar√°:
   - Carga y an√°lisis del dataset
   - EDA con visualizaciones
   - Entrenamiento de m√∫ltiples modelos
   - Comparaci√≥n de rendimiento
   - Selecci√≥n autom√°tica del mejor modelo
   - Guardado de archivos `.pkl`

### Archivos Generados

- `modelo_facial_expressions.pkl`: Modelo entrenado
- `scaler_facial_expressions.pkl`: Scaler para normalizaci√≥n
- `modelo_info.pkl`: Metadata (nombre, m√©tricas, configuraci√≥n)

## üéØ Expresiones Detectadas

El sistema est√° dise√±ado para detectar expresiones faciales gramaticales de Libras:

- **Afirmaci√≥n**: Movimiento de cabeza hacia arriba/abajo
- **Pregunta S√≠/No**: Cejas levantadas, ojos abiertos
- **Pregunta Qu√©/C√≥mo**: Cejas fruncidas
- **Negaci√≥n**: Movimiento de cabeza lateral
- **√ânfasis**: Expresi√≥n facial marcada
- **Duda**: Cejas levantadas, boca ligeramente abierta
- **Condicional**
- **Relativo**
- **T√≥picos**

##  Configuraci√≥n T√©cnica

### MediaPipe Face Mesh

```python
face_mesh = mp_face_mesh.FaceMesh(
    max_num_faces=1,              # Una cara a la vez
    refine_landmarks=True,        # Incluir iris (478 landmarks)
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
)
```

### Landmarks Extra√≠dos

El sistema extrae **100 puntos clave** de los 478 disponibles:

- 17 puntos del contorno facial
- 10 puntos de cejas (5 por ceja)
- 16 puntos de ojos
- 9 puntos de nariz
- 20 puntos de boca (exterior e interior)
- 10 puntos de iris
- 18 puntos adicionales estrat√©gicos

### Vector de Caracter√≠sticas

- **Tama√±o**: 301 valores
  - √çndice 0: Timestamp/Frame ID
  - √çndices 1-300: Coordenadas (x, y, z) de 100 landmarks
- **Formato**: Valores en p√≠xeles (no normalizados por defecto)

##  Rendimiento

El modelo seleccionado autom√°ticamente (t√≠picamente Random Forest) alcanza:

- **Accuracy**: ~95%+ (depende del dataset)
- **F1-Score**: ~95%+
- **Tiempo de predicci√≥n**: <10ms por frame
- **FPS**: 25-30 en tiempo real

##  Personalizaci√≥n

### Ajustar Umbral de Detecci√≥n

En `main_calibrated.py`:

```python
THRESHOLD = 0.47  # Ajustar entre 0.0 y 1.0
```

### Cambiar Tama√±o de Historial de Suavizado

```python
HISTORY_SIZE = 10  # N√∫mero de predicciones a promediar
```

### Modificar Par√°metros de Calibraci√≥n

```python
CALIBRATION_COUNT = 30  # Frames para calibraci√≥n inicial
```

##  Estructura de Datos

### Formato del Dataset CSV

```
0,expression,target
"1390385453.0 x1 y1 z1 x2 y2 z2 ...",affirmative,0
"1390385454.0 x1 y1 z1 x2 y2 z2 ...",yn_question,1
```

##  Troubleshooting

### Error: Webcam no detectada

```bash
# Verificar disponibilidad de c√°mara
python -c "import cv2; print(cv2.VideoCapture(0).isOpened())"
```

### Error: Modelo no encontrado

Aseg√∫rate de ejecutar el notebook `final.ipynb` completo para generar los archivos `.pkl`.

### Baja precisi√≥n en detecci√≥n

1. Mejorar iluminaci√≥n
2. Ajustar el umbral con teclas `+/-`
3. Recalibrar con `ESPACIO`
4. Verificar que el rostro est√© centrado y visible

### Predicciones inestables

Aumentar `HISTORY_SIZE` para mayor suavizado (menor reactividad).

##  Contribuciones

Contribuciones son bienvenidas. Por favor:

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

##  Licencia

Este proyecto es de c√≥digo abierto y est√° disponible bajo la licencia especificada en el repositorio.

##  Autores

- **Alex Villafana** - [@AVillafana12](https://github.com/AVillafana12)


## üìö Referencias

- [MediaPipe Face Mesh](https://google.github.io/mediapipe/solutions/face_mesh.html)
- [Libras - Lengua de Se√±as Brasile√±a](https://es.wikipedia.org/wiki/Lengua_de_se%C3%B1as_brasile%C3%B1a)
- [Scikit-learn Documentation](https://scikit-learn.org/)

##  Contacto

Para preguntas, sugerencias o problemas, por favor abre un issue en el repositorio de GitHub.

---

**Nota**: Este proyecto fue desarrollado como parte de un trabajo final de Machine Learning, enfocado en el reconocimiento de expresiones faciales gramaticales en Lengua de Se√±as.
